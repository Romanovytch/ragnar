{"config":{"lang":["en","fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RAGnaR","text":"<p>Python utilities &amp; CLI to build a high-quality RAG index for CanaR.</p> <ul> <li>\ud83d\udc49 Getting started</li> <li>\ud83d\udc49 CLI reference</li> <li>\ud83d\udc49 Python Library reference</li> <li>\ud83d\udc49 See also: CanaR app (chat UI)</li> </ul>"},{"location":"getting-started/","title":"Getting started","text":"<p>RAGnaR is a data ingestion pipeline used to prepare data for Retrieval Augmented Generation for CanaR.</p>"},{"location":"getting-started/#virtual-env-setup","title":"Virtual env setup","text":"<p>(Optional) First you should use a virtual environment it's best practice:</p> <pre><code>cd RAGnaR\npython -m venv .venv\nsource .venv/bin/activate\n</code></pre>"},{"location":"getting-started/#download-dependencies","title":"Download dependencies","text":"<p>RAGnaR has a <code>requirements.txt</code> listing all the dependencies and their minimal versions and a <code>pyproject.toml</code> as well:</p> <p><pre><code>pip install -U pip\npip install -e .\n</code></pre> Depending on your machine and network, it can take some time.</p>"},{"location":"getting-started/#environement-variables","title":"Environement variables","text":"<p>You can either add the environment variables manually or add them in a <code>.env</code> file at the root of <code>ragnar/</code>.</p> <pre><code># Embedding model env vars\nEMBED_API_BASE=\"https://my-embeddings-model-url/v1\"\nEMBED_API_KEY=\"api-key\"\nEMBED_MODEL=\"model-name\"\n\n# Qdrand env vars\nQDRANT_API_KEY=\"api-key\"\nQDRANT_URL=\"http://qdrant:6333\"\n</code></pre>"},{"location":"getting-started/#data","title":"Data","text":"<p>For now, RAGnaR is only stable for markdown documents ingestion. You will need to clone the repository containing the markdown documents locally.</p> <pre><code>cd ..\ngit clone https://github.com/InseeFrLab/utilitR.git\n</code></pre>"},{"location":"getting-started/#usage","title":"Usage","text":"<p>To launch data ingestion, you can use multiple parameters that are listed by <code>ragnar-ingest --help</code></p> <p><code>--embed-api-base</code>, <code>--embed-api-key</code>, <code>--embed-model</code>, <code>--qdrant-url</code>, <code>--qdrant-api-key</code> don't need to be specified if already set in <code>.env</code>.</p> <p>By default :</p> <ul> <li><code>--target-tokens</code> = 800</li> <li><code>--max-tokens</code> = 1200</li> <li><code>--overlap-tokens</code> = 120</li> </ul> <p>Example of usage : <pre><code># Read all .md from the utilitR project and create a Qdrant collection named \"utilitr_v1\"\nragnar-ingest --repo-path ../utilitR --collection utilitr_v1\n</code></pre></p>"},{"location":"reference/cli/","title":"CLI Reference \u2014 <code>ragnar-ingest</code>","text":"<pre><code>ragnar-ingest --help\n\nusage: Ingest utilitR into Qdrant (remote embeddings) [-h] --repo-path REPO_PATH --collection COLLECTION [--qdrant-url QDRANT_URL] [--qdrant-api-key QDRANT_API_KEY] [--drop-collection]\n                                                      [--target-tokens TARGET_TOKENS] [--overlap-tokens OVERLAP_TOKENS] [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE] [--embed-api-base EMBED_API_BASE]\n                                                      [--embed-api-key EMBED_API_KEY] [--embed-model EMBED_MODEL] [--embed-timeout EMBED_TIMEOUT] [--embed-ca-bundle EMBED_CA_BUNDLE] [--embed-insecure]\n                                                      [--no-progress] [--log-level LOG_LEVEL]\n\noptions:\n  -h, --help            show this help message and exit\n  --repo-path REPO_PATH\n  --collection COLLECTION\n  --qdrant-url QDRANT_URL\n  --qdrant-api-key QDRANT_API_KEY\n  --drop-collection\n  --target-tokens TARGET_TOKENS\n  --overlap-tokens OVERLAP_TOKENS\n  --max-tokens MAX_TOKENS\n  --batch-size BATCH_SIZE\n  --embed-api-base EMBED_API_BASE\n  --embed-api-key EMBED_API_KEY\n  --embed-model EMBED_MODEL\n  --embed-timeout EMBED_TIMEOUT\n  --embed-ca-bundle EMBED_CA_BUNDLE\n  --embed-insecure\n  --no-progress\n  --log-level LOG_LEVEL\n</code></pre> <p>Key options:</p> <ul> <li>--target-tokens, --overlap-tokens, --max-tokens \u2014 chunk sizing</li> <li>--embed-api-base, --embed-model \u2014 remote embedding endpoint/model</li> <li>--batch-size \u2014 embedding/upsert batch</li> <li>--drop-collection \u2014 recreate Qdrant collection</li> <li>--no-progress \u2014 hide progress bars</li> <li>--log-level \u2014 DEBUG/INFO/\u2026</li> </ul>"},{"location":"reference/cli/#ingest-utilitr","title":"Ingest utilitR","text":"<pre><code>ragnar-ingest \\\n  --repo-path ../utilitR \\\n  --collection utilitr_v1 \\\n  --qdrant-url http://localhost:6333 \\\n  --embed-api-base https://api.openai.com/v1 \\\n  --embed-model BAAI/bge-multilingual-gemma2\n</code></pre>"},{"location":"reference/python/","title":"Python Library Reference","text":"<ul> <li>Python Library Reference<ul> <li>chunking<ul> <li>MarkdownChunker<ul> <li>chunk</li> <li>parse_units</li> </ul> </li> </ul> </li> <li>remote<ul> <li>RemoteOpenAIEncoder<ul> <li>dim</li> <li>encode</li> </ul> </li> </ul> </li> <li>qdrant_store<ul> <li>ensure_collection_dense</li> <li>search_dense</li> <li>upsert_dense</li> </ul> </li> <li>utilitr<ul> <li>UtilitrSource<ul> <li>iter_docs</li> </ul> </li> </ul> </li> <li>ingest_utilitr</li> </ul> </li> </ul>"},{"location":"reference/python/#ragnar.chunking","title":"<code>ragnar.chunking</code>","text":""},{"location":"reference/python/#ragnar.chunking.MarkdownChunker","title":"<code>MarkdownChunker</code>","text":"<p>Chunk Markdown into model-friendly pieces while preserving code fences.</p> <p>Chunks are assembled from paragraph and fenced-code units with a soft target size and a hard ceiling. Code fences are never split.</p> <p>Parameters:</p> Name Type Description Default <code>target_tokens</code> <p>Soft target size for a chunk (tokens).</p> <code>800</code> <code>overlap_tokens</code> <p>Max paragraph-only overlap between consecutive chunks.</p> <code>120</code> <code>max_tokens</code> <p>Hard ceiling for a chunk size (tokens).</p> <code>1200</code>"},{"location":"reference/python/#ragnar.chunking.MarkdownChunker.chunk","title":"<code>chunk(units)</code>","text":"<p>Pack units into chunks with soft/hard token budgets and paragraph-only overlap.</p> <p>Chunks are built greedily from <code>Unit</code>s (paragraphs and code fences). We never split inside a unit, so code fences remain intact. When starting a new chunk, we optionally prepend the last paragraph from the previous chunk (if it fits the <code>overlap_tokens</code> budget) to preserve continuity. Code is never overlapped.</p> <p>Cutting rules:</p> <p>1) If adding a unit would exceed <code>max_tokens</code>: close current chunk. 2) If already &gt;= <code>target_tokens</code> and next unit is a paragraph: close chunk (soft cut). 3) Otherwise, keep appending.</p> <p>The chunk's <code>heading_path</code> is taken from the last unit it contains.</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>List[Unit]</code> <p>Units from <code>parse_units()</code>.</p> required <p>Returns:</p> Type Description <code>List[tuple[str, List[tuple[int, str]]]]</code> <p>A list of <code>(chunk_text, heading_path)</code> pairs in order.</p>"},{"location":"reference/python/#ragnar.chunking.MarkdownChunker.parse_units","title":"<code>parse_units(text)</code>","text":"<p>Parse Markdown into atomic units (paragraphs and fenced code).</p> <p>The parser walks the Markdown-It token stream, producing <code>Unit</code> objects:</p> <ul> <li><code>kind=\"para\"</code> for paragraphs and for flattened blocks (lists, blockquotes, tables).</li> <li><code>kind=\"code\"</code> for fenced code blocks; fences are kept whole and never split.</li> </ul> <p>Each unit carries a <code>heading_path</code> (list of <code>(level, title)</code> tuples) reflecting the active H1/H2/... when the unit was encountered.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Raw Markdown source.</p> required <p>Returns:</p> Type Description <code>List[Unit]</code> <p>A list of <code>Unit</code> objects in document order.</p> Notes <ul> <li>Lists and tables are flattened by concatenating their inline text.</li> <li>Code fences are reconstructed as Markdown (triple backticks), and <code>lang</code> is taken from the fence info string.</li> </ul>"},{"location":"reference/python/#ragnar.embeddings.remote","title":"<code>ragnar.embeddings.remote</code>","text":""},{"location":"reference/python/#ragnar.embeddings.remote.RemoteOpenAIEncoder","title":"<code>RemoteOpenAIEncoder</code>","text":"<p>Minimal client for OpenAI-compatible <code>/v1/embeddings</code>.</p> <p>Sends batched POST requests to <code>{api_base}/embeddings</code>, returns a NumPy array of L2-normalized embeddings suitable for cosine search in vector databases (e.g., Qdrant).</p> <p>Normalization ensures dot product \u2261 cosine similarity.</p> <p>Parameters:</p> Name Type Description Default <code>api_base</code> <code>str</code> <p>Base URL of the OpenAI-compatible API (e.g., \"https://api.openai.com/v1\").</p> required <code>model</code> <code>str</code> <p>Embedding model identifier understood by the server (e.g., \"BAAI/bge-multilingual-gemma2\").</p> required <code>api_key</code> <code>str</code> <p>Optional bearer token (\"Authorization: Bearer ...\").</p> <code>''</code> <code>timeout</code> <code>float</code> <p>Per-request timeout in seconds.</p> <code>60.0</code> <code>ca_bundle</code> <code>Optional[str]</code> <p>Path to a custom CA bundle (PEM) for TLS verification.</p> <code>None</code> <code>insecure</code> <code>bool</code> <p>If True, disables TLS verification (use only for local testing).</p> <code>False</code> Note <p>Uses a persistent :class:<code>requests.Session</code> for connection pooling.</p>"},{"location":"reference/python/#ragnar.embeddings.remote.RemoteOpenAIEncoder.dim","title":"<code>dim</code>  <code>property</code>","text":"<p>Return the embedding dimensionality (D), probing once if unknown.</p> <p>On first access, performs a minimal embedding request (:meth:<code>encode</code> on a single short string) to discover D and caches it.</p> <p>Returns:</p> Type Description <code>int</code> <p>The embedding dimensionality as an integer.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the embeddings API returns a non-200 response during the probe request.</p>"},{"location":"reference/python/#ragnar.embeddings.remote.RemoteOpenAIEncoder.encode","title":"<code>encode(texts, batch_size=64)</code>","text":"<p>Embed a list of strings and return L2-normalized vectors.</p> <p>Batches the input to reduce request size, performs POST requests to <code>/embeddings</code>, collects the <code>embedding</code> fields, converts to float32, and normalizes each vector to unit length.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>List[str]</code> <p>List of input strings to embed (order preserved).</p> required <code>batch_size</code> <code>int</code> <p>Number of texts per request batch.</p> <code>64</code> <p>Returns:</p> Type Description <p>A NumPy array of shape <code>(len(texts), D)</code> with dtype <code>float32</code>,</p> <p>where each row is L2-normalized.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the embeddings API returns a non-200 response.</p> Notes <ul> <li>The server must return a JSON object with a <code>data</code> list of   <code>{ \"embedding\": [...] }</code> items, one per input string.</li> <li>Normalization uses a small epsilon (1e-12) to avoid division by zero.</li> </ul>"},{"location":"reference/python/#ragnar.vectorstores.qdrant_store","title":"<code>ragnar.vectorstores.qdrant_store</code>","text":""},{"location":"reference/python/#ragnar.vectorstores.qdrant_store.ensure_collection_dense","title":"<code>ensure_collection_dense(client, name, dim, drop=False)</code>","text":"<p>Ensure a dense-vector collection exists with cosine distance.</p> <p>Creates (or optionally recreates) a collection configured for a single unnamed vector of size <code>dim</code> using cosine distance\u2014appropriate for L2-normalized embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>QdrantClient</code> <p>Initialized Qdrant client.</p> required <code>name</code> <code>str</code> <p>Collection name.</p> required <code>dim</code> <code>int</code> <p>Embedding dimensionality (D).</p> required <code>drop</code> <code>bool</code> <p>If True and the collection exists, delete it before creating.</p> <code>False</code> Notes <ul> <li>If the collection already exists and <code>drop=False</code>, this function   leaves it as-is (no schema validation).</li> <li>Cosine distance is recommended when you L2-normalize vectors   (dot product becomes equivalent to cosine similarity).</li> </ul>"},{"location":"reference/python/#ragnar.vectorstores.qdrant_store.search_dense","title":"<code>search_dense(client, collection, query_vec, top_k=5, source=None)</code>","text":"<p>Search nearest chunks by vector, optionally filtering by source. For testing.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>QdrantClient</code> <p>Qdrant client.</p> required <code>collection</code> <code>str</code> <p>Collection name.</p> required <code>query_vec</code> <code>list[float]</code> <p>Query embedding as a list (or 1D array) of floats.</p> required <code>top_k</code> <code>int</code> <p>Maximum number of results to return.</p> <code>5</code> <code>source</code> <code>str | None</code> <p>Optional payload filter on <code>payload['source']</code> (e.g., \"utilitr\").</p> <code>None</code> <p>Returns:</p> Type Description <p>A list of Qdrant <code>ScoredPoint</code> objects with <code>.score</code> and <code>.payload</code>.</p> Example <p>hits = search_dense(client, \"utilitr_v1\", qvec, top_k=5, source=\"utilitr\") urls = [h.payload.get(\"url\") for h in hits]</p>"},{"location":"reference/python/#ragnar.vectorstores.qdrant_store.upsert_dense","title":"<code>upsert_dense(client, collection, chunks, vectors, start_index=0)</code>","text":"<p>Upsert points (vector + payload) for the given chunks.</p> <p>Each chunk is stored as a single point with:</p> <ul> <li><code>id</code>: chunk.id (must be an unsigned integer or a UUID string)</li> <li><code>vector</code>: vectors[j] (list of floats)</li> <li><code>payload</code>: chunk.metadata plus the raw <code>text</code> (for RAG)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>QdrantClient</code> <p>Qdrant client.</p> required <code>collection</code> <code>str</code> <p>Target collection name.</p> required <code>chunks</code> <code>List[Chunk]</code> <p>Chunks to write. The order must match <code>vectors</code>.</p> required <code>vectors</code> <code>ndarray</code> <p>2D NumPy array of shape (N, D), one row per chunk.</p> required <code>start_index</code> <code>int</code> <p>Reserved for future use (e.g., paging); currently unused.</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of chunks and vectors differs.</p> <code>UnexpectedResponse</code> <p>If Qdrant rejects the upsert.</p> Notes <ul> <li>Qdrant point IDs must be either an unsigned integer or a UUID string.   Ensure your <code>Chunk.id</code> respects that (we recommend UUIDs).</li> <li>The raw chunk text is stored in payload as <code>\"text\"</code>, enabling direct   answer assembly or debugging without an extra store.</li> </ul>"},{"location":"reference/python/#ragnar.sources.utilitr","title":"<code>ragnar.sources.utilitr</code>","text":""},{"location":"reference/python/#ragnar.sources.utilitr.UtilitrSource","title":"<code>UtilitrSource</code>","text":"<p>Iterate over utilitR Markdown/Quarto documents with rich metadata.</p> <p>This adapter expects a local clone of the utilitR repository. It discovers <code>*.md</code> and <code>*.qmd</code> files (excluding build/system directories), splits away YAML frontmatter, infers a document title when missing, and constructs stable URLs for both the public book (<code>source_url</code>) and GitHub (<code>repo_url</code>) pinned to the current commit.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>Path</code> <p>Path to the local utilitR repository clone.</p> required <code>base_url</code> <code>str</code> <p>Base URL of the published Quarto book (used to build <code>source_url</code> for each document). A trailing slash is ensured.</p> <code>'https://book.utilitr.org/'</code> <p>Attributes:</p> Name Type Description <code>repo_path</code> <p>Normalized repository path.</p> <code>base_url</code> <p>Normalized base URL (with trailing slash).</p> <code>commit</code> <p>Current git commit hash of the repository (or None if unknown).</p> Note <p>The iterator yields <code>DocRecord(text, metadata)</code> for each discovered file. Downstream, the chunker will split <code>text</code> into atomic units while preserving <code>metadata</code> for citations.</p>"},{"location":"reference/python/#ragnar.sources.utilitr.UtilitrSource.iter_docs","title":"<code>iter_docs()</code>","text":"<p>Yield <code>DocRecord</code> items for each relevant Markdown/Quarto file.</p> <p>Discovery rules:</p> <ul> <li>Include: all <code>**/*.md</code>, <code>**/*.qmd</code>.</li> <li>Exclude directories: {\".git\", \"_book\", \"docs\", \".quarto\", \"renv\", \".github\"}.</li> </ul> <p>For each file:</p> <ol> <li>Read raw text and split YAML frontmatter (via <code>extract_frontmatter</code>).</li> <li>Determine title:<ul> <li>from frontmatter <code>title</code>, or</li> <li>from the first Markdown <code># Heading</code>, or</li> <li>fallback to the filename stem.</li> </ul> </li> <li>Compute URLs:<ul> <li><code>source_url</code> \u2192 <code>{base_url}/{relative}.html</code></li> <li><code>repo_url</code>   \u2192 GitHub blob URL pinned to <code>{commit}</code> (or \"main\").</li> </ul> </li> </ol> <p>Yields:</p> Name Type Description <code>DocRecord</code> <code>Iterable[DocRecord]</code> <p><code>text</code>=Markdown body (no frontmatter), <code>metadata</code> with keys</p> <code>Iterable[DocRecord]</code> <p>described in the class docstring.</p> <p>Example:</p> <pre><code>&gt;&gt;&gt; src = UtilitrSource(Path(\"../utilitR\"))\n&gt;&gt;&gt; doc = next(iter(src.iter_docs()))\n&gt;&gt;&gt; (\"doc_title\" in doc.metadata, doc.metadata[\"source\"])\n(True, \"utilitr\")\n</code></pre>"},{"location":"reference/python/#ragnar.ingest_utilitr","title":"<code>ragnar.ingest_utilitr</code>","text":"<p>RAGnaR \u2014 utilitR ingestion CLI.</p> <p>This script builds a dense retrieval index from the utilitR repository: 1) loads Markdown/Quarto docs (frontmatter removed) with rich metadata, 2) chunks them into model-friendly pieces (paragraphs + fenced code), 3) embeds chunks via a remote OpenAI-compatible /v1/embeddings endpoint, 4) upserts vectors + payloads into a Qdrant collection.</p> Typical use <p>ragnar-ingest         --repo-path ../utilitR         --collection utilitr_v1         --qdrant-url http://localhost:6333         --embed-api-base https://api.openai.com/v1         --embed-model BAAI/bge-multilingual-gemma2         --drop-collection</p> <p>Environment: - EMBED_API_BASE / EMBED_API_KEY / EMBED_MODEL (optional CLI overrides) - QDRANT_URL / QDRANT_API_KEY (optional CLI overrides)</p> <p>Outputs: - A Qdrant collection with one point per chunk (cosine distance),   payload includes: source, chapter/section, breadcrumbs, urls, token_count, text. - Console stats (docs, chunks, token distribution, throughput).</p>"},{"location":"fr/","title":"RAGnaR","text":"<p>Outils Python &amp; CLI pour construire un index RAG de qualit\u00e9 pour CanaR.</p> <ul> <li>\ud83d\udc49 Bien d\u00e9marrer</li> <li>\ud83d\udc49 R\u00e9f\u00e9rence CLI</li> <li>\ud83d\udc49 R\u00e9f\u00e9rence biblioth\u00e8que python</li> <li>\ud83d\udc49 Voir aussi : application CanaR (UI de chat)</li> </ul>"},{"location":"fr/getting-started/","title":"Bien d\u00e9marrer","text":"<p>RAGnaR est une pipeline d'ingestion de donn\u00e9es en CLI qui permet de faire du RAG sur l'application CanaR</p>"},{"location":"fr/getting-started/#initialisation-de-lenvironnement-virtuel","title":"Initialisation de l'environnement virtuel","text":"<p>(Optionnel) C'est une bonne pratique, en python, d'utiliser un environnement virtuel :</p> <pre><code>cd RAGnaR\npython -m venv .venv\nsource .venv/bin/activate\n</code></pre>"},{"location":"fr/getting-started/#installer-les-dependances","title":"Installer les d\u00e9pendances","text":"<p>RAGnaR a un <code>requirements.txt</code> listant toutes les d\u00e9pendances et leur version minimale ainsi qu'un <code>pyproject.toml</code> :</p> <pre><code>pip install -U pip\npip install -e .\n</code></pre> <p>Selon votre machine et votre r\u00e9seau, cette op\u00e9ration peut prendre quelques minutes.</p>"},{"location":"fr/getting-started/#variables-denvironnement","title":"Variables d'environnement","text":"<p>Vous pouvez sp\u00e9cifier les variables d'environnement dans un fichier <code>.env</code> \u00e0 la racine du projet. Le fichier <code>.env.example</code> vous donne un exemple de ce \u00e0 quoi il devrait ressembler :</p> <pre><code># Embeddings\nEMBED_API_BASE=\"https://my-embeddings-model-url/v1\"\nEMBED_API_KEY=\"api-key\"\nEMBED_MODEL=\"model-name\"\n\n# Qdrant\nQDRANT_API_KEY=\"api-key\"\nQDRANT_URL=\"http://qdrant:6333\"\n</code></pre>"},{"location":"fr/getting-started/#donnees","title":"Donn\u00e9es","text":"<p>En l'\u00e9tat, RAGnaR ne supporte que les documents markdown dans un dossier local. Il faut donc cloner le projet \u00e0 c\u00f4t\u00e9 :</p> <pre><code>cd ..\ngit clone https://github.com/InseeFrLab/utilitR.git\n</code></pre>"},{"location":"fr/getting-started/#utilisation","title":"Utilisation","text":"<p>Pour lancer l'ingestion des donn\u00e9es, vous pouvez utiliser les param\u00e8tres list\u00e9s par <code>ragnar-ingest --help</code> :</p> <pre><code>usage: Ingest utilitR into Qdrant (remote embeddings) [-h] --repo-path REPO_PATH --collection COLLECTION [--qdrant-url QDRANT_URL] [--qdrant-api-key QDRANT_API_KEY] [--drop-collection]\n                                                      [--target-tokens TARGET_TOKENS] [--overlap-tokens OVERLAP_TOKENS] [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE] [--embed-api-base EMBED_API_BASE]\n                                                      [--embed-api-key EMBED_API_KEY] [--embed-model EMBED_MODEL] [--embed-timeout EMBED_TIMEOUT] [--embed-ca-bundle EMBED_CA_BUNDLE] [--embed-insecure]\n                                                      [--no-progress] [--log-level LOG_LEVEL]\n\noptions:\n  -h, --help            show this help message and exit\n  --repo-path REPO_PATH\n  --collection COLLECTION\n  --qdrant-url QDRANT_URL\n  --qdrant-api-key QDRANT_API_KEY\n  --drop-collection\n  --target-tokens TARGET_TOKENS\n  --overlap-tokens OVERLAP_TOKENS\n  --max-tokens MAX_TOKENS\n  --batch-size BATCH_SIZE\n  --embed-api-base EMBED_API_BASE\n  --embed-api-key EMBED_API_KEY\n  --embed-model EMBED_MODEL\n  --embed-timeout EMBED_TIMEOUT\n  --embed-ca-bundle EMBED_CA_BUNDLE\n  --embed-insecure\n  --no-progress         Disable progress bars\n  --log-level LOG_LEVEL\n                        DEBUG, INFO, WARNING, ERROR\n</code></pre> <p><code>--embed-api-base</code>, <code>--embed-api-key</code>, <code>--embed-model</code>, <code>--qdrant-url</code>, <code>--qdrant-api-key</code> n'ont pas besoin d'\u00eatre sp\u00e9cifi\u00e9s s'ils sont d\u00e9finis dans le <code>.env</code>.</p> <p>Par d\u00e9faut : * <code>--target-tokens</code> = 800 * <code>--max-tokens</code> = 1200 * <code>--overlap-tokens</code> = 120</p> <p>Exemple d'utilisation : <pre><code># Lit tous les fichiers markdown (.md) du repo et cr\u00e9e une collection Qdrant \"utilitr_v1\"\nragnar-ingest --repo-path ../utilitR --collection utilitr_v1\n</code></pre></p>"}]}